{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1530ad",
   "metadata": {},
   "source": [
    "1.Absolute Maximum Scaling\n",
    "range to -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b53e0cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Sales</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E002</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Diploma</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E003</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Master</td>\n",
       "      <td>Sales</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E004</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>IT</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E005</td>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Master</td>\n",
       "      <td>HR</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EmployeeID  Experience   Age Education_Level Department   Salary\n",
       "0       E001         1.0  22.0        Bachelor      Sales  25000.0\n",
       "1       E002         3.0  25.0         Diploma  Marketing  30000.0\n",
       "2       E003         5.0  28.0          Master      Sales  42000.0\n",
       "3       E004         7.0  35.0        Bachelor         IT  52000.0\n",
       "4       E005        10.0  40.0          Master         HR  60000.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('employee_salary.csv')\n",
    "\n",
    "df.select_dtypes(include= np.number)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Absolute Maximum Scaling\n",
    "max_abs = np.max(np.abs(df), axis=0)\n",
    "\n",
    "scaled_df = df / max_abs\n",
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09fd819",
   "metadata": {},
   "source": [
    "Min-Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f0d7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experience</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Sales</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Diploma</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Master</td>\n",
       "      <td>Sales</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>IT</td>\n",
       "      <td>52000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Master</td>\n",
       "      <td>HR</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experience   Age Education_Level Department   Salary\n",
       "0         1.0  22.0        Bachelor      Sales  25000.0\n",
       "1         3.0  25.0         Diploma  Marketing  30000.0\n",
       "2         5.0  28.0          Master      Sales  42000.0\n",
       "3         7.0  35.0        Bachelor         IT  52000.0\n",
       "4        10.0  40.0          Master         HR  60000.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Department'].unique()\n",
    "\n",
    "# df.info()\n",
    "\n",
    "#check dublicate\n",
    "df.duplicated()\n",
    "\n",
    "\n",
    "# remove unusless columns\n",
    "df2 =df.drop(columns=['EmployeeID'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fdbceef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experience         4\n",
       "Age                4\n",
       "Education_Level    4\n",
       "Department         4\n",
       "Salary             3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count missing values\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d3b201e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experience         0\n",
       "Age                0\n",
       "Education_Level    0\n",
       "Department         0\n",
       "Salary             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop missing value\n",
    "df3 = df2.dropna()\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506add0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2ce361e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'E001'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_9884\\3309432184.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m sklearn.preprocessing \u001b[38;5;28;01mimport\u001b[39;00m  MinMaxScaler\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m scaled = MinMaxScaler()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m scaled.fit_transform(df)\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m scaled_df = pd.DataFrame(scaled, columns=df.columns)\n\u001b[32m      7\u001b[39m print(scaled_df.head())\n",
      "\u001b[32mc:\\Users\\shaikh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m     @wraps(f)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m wrapped(self, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         data_to_wrap = f(self, X, *args, **kwargs)\n\u001b[32m    317\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m isinstance(data_to_wrap, tuple):\n\u001b[32m    318\u001b[39m             \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m             return_tuple = (\n",
      "\u001b[32mc:\\Users\\shaikh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    890\u001b[39m                 )\n\u001b[32m    891\u001b[39m \n\u001b[32m    892\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    893\u001b[39m             \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, **fit_params).transform(X)\n\u001b[32m    895\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    896\u001b[39m             \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    897\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[32mc:\\Users\\shaikh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    450\u001b[39m             Fitted scaler.\n\u001b[32m    451\u001b[39m         \"\"\"\n\u001b[32m    452\u001b[39m         \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    453\u001b[39m         self._reset()\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m self.partial_fit(X, y)\n",
      "\u001b[32mc:\\Users\\shaikh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32mc:\\Users\\shaikh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    490\u001b[39m \n\u001b[32m    491\u001b[39m         xp, _ = get_namespace(X)\n\u001b[32m    492\u001b[39m \n\u001b[32m    493\u001b[39m         first_pass = \u001b[38;5;28;01mnot\u001b[39;00m hasattr(self, \u001b[33m\"n_samples_seen_\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m         X = validate_data(\n\u001b[32m    495\u001b[39m             self,\n\u001b[32m    496\u001b[39m             X,\n\u001b[32m    497\u001b[39m             reset=first_pass,\n",
      "\u001b[32mc:\\Users\\shaikh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2950\u001b[39m             out = y\n\u001b[32m   2951\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2952\u001b[39m             out = X, y\n\u001b[32m   2953\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m         out = check_array(X, input_name=\u001b[33m\"X\"\u001b[39m, **check_params)\n\u001b[32m   2955\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m         out = _check_y(y, **check_params)\n\u001b[32m   2957\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32mc:\\Users\\shaikh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) from complex_warning\n",
      "\u001b[32mc:\\Users\\shaikh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\shaikh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   1996\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __array__(self, dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> np.ndarray:\n\u001b[32m   1997\u001b[39m         values = self._values\n\u001b[32m-> \u001b[39m\u001b[32m1998\u001b[39m         arr = np.asarray(values, dtype=dtype)\n\u001b[32m   1999\u001b[39m         if (\n\u001b[32m   2000\u001b[39m             astype_is_view(values.dtype, arr.dtype)\n\u001b[32m   2001\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write()\n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'E001'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "\n",
    "scaled = MinMaxScaler()\n",
    "scaled.fit_transform(df)\n",
    "\n",
    "scaled_df = pd.DataFrame(scaled, columns=df.columns)\n",
    "print(scaled_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
